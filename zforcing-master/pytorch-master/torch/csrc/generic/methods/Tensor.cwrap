// TODO: check that there are no args
[[
  name: THPTensor_(elementSize)
  python_name: element_size
  cpu_half: True
  auto_gpu: False
  only_register: True
]]
static PyObject * THPTensor_(elementSize)(THPTensor *self, PyObject *args)
{
  return PyLong_FromLongLong(THStorage_(elementSize)(LIBRARY_STATE_NOARGS));
}

// TODO: check that there are no args
[[
  name: THPTensor_(storage)
  python_name: storage
  cpu_half: True
  auto_gpu: False
  only_register: True
]]
static PyObject * THPTensor_(storage)(THPTensor *self, PyObject *args)
{
  // TODO: memory leak on error
  THStorage *result = THTensor_(storage)(LIBRARY_STATE self->cdata);
  if (result == NULL)
    Py_RETURN_NONE;
  THStorage_(retain)(LIBRARY_STATE result);
  THStoragePtr _tmp = result;
  PyObject *ret = THPStorage_(New)(result);
  _tmp.release();
  return ret;
}

[[
  name: storageOffset
  python_name: storage_offset
  cpu_half: True
  auto_gpu: False
  return: int64_t
  arguments:
    - THTensor* self
]]

[[
  name: nDimension
  python_name: ndimension
  cpu_half: True
  auto_gpu: False
  return: int64_t
  arguments:
    - THTensor* self
]]
[[
  name: THPTensor_(nDimension)
  python_name: dim
  cpu_half: True
  auto_gpu: False
  only_register: True
  method_flags: METH_KEYWORDS
]]

[[
  python_name: index
  name: THPTensor_(getValue)<true>
  only_register: True
  override_method_flags: METH_O
]]

[[
  python_name: _set_index
  name: THPTensor_(setIndex)
  only_register: True
]]
PyObject * THPTensor_(setIndex)(THPTensor *self, PyObject *args)
{
  THPUtils_assert(PyTuple_GET_SIZE(args) == 2, "set_index takes exactly two "
      "arguments (%d given)", (int)PyTuple_GET_SIZE(args));
  if (THPTensor_(setValue)<true>(self, PyTuple_GET_ITEM(args, 0), PyTuple_GET_ITEM(args, 1)) != 0)
    return NULL;
  Py_RETURN_NONE;
}

[[
  name: resize_
  return: self
  cname: resize
  cpu_half: True
  arguments:
    - THTensor* self
    - arg: THSize* size
      long_args: True
    - CONSTANT NULL
]]

[[
  name: zeros
  only_stateless: True
  auto_gpu: False
  return: argument 0
  arguments:
    - arg: THTensor* result
      output: True
    - arg: THSize* size
      long_args: True
]]

[[
  name: ones
  only_stateless: True
  auto_gpu: False
  return: argument 0
  arguments:
    - arg: THTensor* result
      output: True
    - arg: THSize* size
      long_args: True
]]

[[
  name: numel
  return: int64_t
  cname: nElement
  cpu_half: True
  auto_gpu: False
  with_stateless: True
  arguments:
    - THTensor* self
]]
[[
  name: THPTensor_(numel)
  python_name: nelement
  cpu_half: True
  auto_gpu: False
  only_register: True
  method_flags: METH_KEYWORDS
]]

[[
  name: set_
  cname: set
  cpu_half: True
  auto_gpu: False
  return: argument 0
  options:
    - cname: set
      arguments:
        - THTensor* self
        - THTensor* source
    - cname: setStorage
      arguments:
        - THTensor* self
        - CONSTANT NULL, 0, NULL, NULL
    - cname: setStorage
      before_call: THLongStoragePtr __storage_size = THLongStorage_newWithSize1(THStorage_(size)(LIBRARY_STATE arg_storage));
      arguments:
        - THTensor* self
        - THStorage* storage
        - CONSTANT 0
        - CONSTANT __storage_size.get()
        - CONSTANT NULL
    - cname: setStorage
      arguments:
        - THTensor* self
        - THStorage* sourceStorage
        - int64_t storage_offset
        - arg: THSize* size
          long_args: True
        - CONSTANT NULL
    - cname: setStorage
      arguments:
        - THTensor* self
        - THStorage* sourceStorage
        - int64_t storage_offset
        - THSize* size
        - THStride* strides
]]

[[
  name: THPTensor_(select)
  python_name: select
  cpu_half: True
  auto_gpu: False
  only_register: True
]]
static PyObject * THPTensor_(select)(THPTensor *self, PyObject *args)
{
  HANDLE_TH_ERRORS
  int64_t dim, idx;
  if (!PyArg_ParseTuple(args, "LL", &dim, &idx))
    return NULL;

  int ndim = THTensor_(nDimension)(LIBRARY_STATE self->cdata);

  THPUtils_assert(dim >= -(ndim) && dim < (ndim),
    "dimension out of range (expected to be in range of [%d, %d], but got %d)",
    -(ndim), (ndim)-1, dim);
  if (dim<0) dim += ndim;

  if(ndim > 1) {
    THTensorPtr selected = THTensor_(newWithTensor)(LIBRARY_STATE self->cdata);
    THTensor_(select)(LIBRARY_STATE selected.get(), NULL, (int) dim, idx);
    return THPTensor_(New)(selected.release());
  }
  else {
    THArgCheck(ndim == 1, 1, "empty Tensor");
    return THPUtils_(newReal)(THTensor_(get1d)(LIBRARY_STATE self->cdata, idx));
  }
  END_HANDLE_TH_ERRORS
}

PyObject * THPTensor_(size)(PyObject *self, PyObject *args, PyObject *kwargs)
{
  HANDLE_TH_ERRORS
  THTensor* tensor = ((THPTensor*)self)->cdata;
  if (PyTuple_Size(args) == 0 && (!kwargs || PyDict_Size(kwargs) == 0)) {
    return THPSize_New(tensor->nDimension, tensor->size);
  }

  int tuplecount = args ? (int) PyTuple_Size(args) : 0;
  int dictcount = kwargs ? (int) PyDict_Size(kwargs) : 0;

  PyObject* pydim = NULL;
  if (tuplecount == 1 && dictcount == 0) {
    pydim = PyTuple_GET_ITEM(args, 0);
  } else if (dictcount == 1 && tuplecount == 0) {
    pydim = PyDict_GetItemString(kwargs, "dim");
  }

  if (pydim && THPUtils_checkLong(pydim)) {
    int dim = (int)THPUtils_unpackLong(pydim);
    if (dim < 0)
      dim += tensor->nDimension;
    return PyLong_FromLongLong(THTensor_(size)(LIBRARY_STATE tensor, dim));
  }

  THPUtils_invalidArguments(args, kwargs, "size", 2, "(int dim)", "no arguments");
  return NULL;
  END_HANDLE_TH_ERRORS
}
[[
  name: THPTensor_(size)
  python_name: size
  cpu_half: True
  auto_gpu: False
  method_flags: METH_KEYWORDS
  only_register: True
]]

PyObject * THPTensor_(stride)(PyObject *self, PyObject *args, PyObject *kwargs)
{
  HANDLE_TH_ERRORS
  THTensor* tensor = ((THPTensor*)self)->cdata;
  if (PyTuple_Size(args) == 0 && (!kwargs || PyDict_Size(kwargs) == 0)) {
    PyObject* stride = PyTuple_New(tensor->nDimension);
    for (int i = 0; i != tensor->nDimension; ++i) {
      PyTuple_SET_ITEM(stride, i, PyLong_FromLongLong(tensor->stride[i]));
    }
    return stride;
  }

  int tuplecount = args ? (int) PyTuple_Size(args) : 0;
  int dictcount = kwargs ? (int) PyDict_Size(kwargs) : 0;

  PyObject* pydim = NULL;
  if (tuplecount == 1 && dictcount == 0) {
    pydim = PyTuple_GET_ITEM(args, 0);
  } else if (dictcount == 1 && tuplecount == 0) {
    pydim = PyDict_GetItemString(kwargs, "dim");
  }

  if (pydim && THPUtils_checkLong(pydim)) {
    int dim = (int)THPUtils_unpackLong(pydim);
    if (dim < 0)
      dim += tensor->nDimension;
    return PyLong_FromLongLong(THTensor_(stride)(LIBRARY_STATE tensor, dim));
  }

  THPUtils_invalidArguments(args, kwargs, "stride", 2, "(int dim)", "no arguments");
  return NULL;
  END_HANDLE_TH_ERRORS
}
[[
  name: THPTensor_(stride)
  python_name: stride
  cpu_half: True
  auto_gpu: False
  method_flags: METH_KEYWORDS
  only_register: True
]]

[[
  name: fill_
  cname: fill
  return: self
  arguments:
    - THTensor* self
    - real value
]]

[[
  name: isSameSizeAs
  python_name: is_same_size
  cpu_half: True
  auto_gpu: False
  return: bool
  arguments:
    - THTensor* self
    - THTensor* other
]]

[[
  name: isContiguous
  python_name: is_contiguous
  cpu_half: True
  auto_gpu: False
  return: bool
  arguments:
    - THTensor* self
]]

[[
  name: isSetTo
  python_name: is_set_to
  cpu_half: True
  auto_gpu: False
  return: bool
  arguments:
    - THTensor* self
    - THTensor* tensor
]]

[[
  name: maskedFill_
  cname: maskedFill
  python_name: masked_fill_
  return: self
  arguments:
    - THTensor* self
    - THBoolTensor* mask
    - real value
]]

[[
  name: maskedCopy_
  cname: maskedCopy
  python_name: masked_copy_
  return: self
  arguments:
    - THTensor* self
    - THBoolTensor* mask
    - THTensor* source
]]

[[
  name: maskedSelect
  python_name: masked_select
  with_stateless: True
  return: argument 0
  arguments:
    - arg: THTensor* result
      output: True
    - THTensor* self
    - THBoolTensor* mask
]]

[[
  name: transpose
  with_stateless: True
  cname: newTranspose
  cpu_half: True
  auto_gpu: False
  return: THTensor*
  arguments:
    - THTensor* self
    - arg: int64_t dim0
      wrap_dim: self
    - arg: int64_t dim1
      wrap_dim: self
]]

[[
  name: transpose_
  cname: transpose
  cpu_half: True
  auto_gpu: False
  return: self
  arguments:
    - THTensor* self
    - THTensor* self
    - arg: int64_t dim0
      wrap_dim: self
    - arg: int64_t dim1
      wrap_dim: self
]]

[[
  name: t
  with_stateless: True
  auto_gpu: False
  cname: newTranspose
  return: THTensor*
  before_call: |
    int64_t ndim = arg_self->nDimension;
    THPUtils_assert(ndim == 2, "t() expects a 2D tensor, but self is %ldD", ndim);
  arguments:
    - THTensor* self
    - CONSTANT 0
    - CONSTANT 1
]]

[[
  name: t_
  cname: transpose
  auto_gpu: False
  return: self
  before_call: |
    int64_t ndim = arg_self->nDimension;
    THPUtils_assert(ndim == 2, "t_() expects a 2D tensor, but self is %ldD", ndim);
  arguments:
    - THTensor* self
    - THTensor* self
    - CONSTANT 0
    - CONSTANT 1
]]

[[
  name: squeeze
  cpu_half: True
  with_stateless: True
  return: argument 0
  options:
    - arguments:
        - arg: THTensor* result
          output: True
        - THTensor* self
    - cname: squeeze1d
      arguments:
        - arg: THTensor* result
          output: True
        - THTensor* self
        - arg: int64_t dim
          wrap_dim: self
]]

[[
  name: squeeze_
  cpu_half: True
  return: self
  options:
    - cname: squeeze
      arguments:
        - THTensor* self
        - THTensor* self
    - cname: squeeze1d
      arguments:
        - THTensor* self
        - THTensor* self
        - arg: int64_t dim
          wrap_dim: self
]]

[[
  name: unsqueeze
  with_stateless: True
  cpu_half: True
  auto_gpu: False
  return: argument 0
  cname: unsqueeze1d
  arguments:
    - arg: THTensor* result
      output: True
    - THTensor* self
    - arg: int64_t dim
      wrap_dim: self+1
]]

[[
  name: unsqueeze_
  cpu_half: True
  auto_gpu: False
  return: self
  cname: unsqueeze1d
  arguments:
    - THTensor* self
    - THTensor* self
    - arg: int64_t dim
      wrap_dim: self+1
]]

[[
  name: nonzero
  with_stateless: True
  return: argument 0
  arguments:
    - arg: THIndexTensor* result
      output: True
    - THTensor* self
]]

[[
  name: contiguous
  cname: newContiguous
  return: THTensor*
  arguments:
    - THTensor* self
]]

[[
  name: clone
  cname: newClone
  return: THTensor*
  arguments:
    - THTensor* self
]]

[[
  name: view
  cname: newView
  auto_gpu: False
  return: THTensor*
  arguments:
    - THTensor* self
    - arg: THSize* size
      long_args: True
]]

[[
  name: expand
  cname: newExpand
  return: THTensor*
  arguments:
    - THTensor* self
    - arg: THSize* size
      long_args: True
]]

[[
  name: resizeAs_
  python_name: resize_as_
  cname: resizeAs
  return: self
  arguments:
    - THTensor* self
    - THTensor* template
]]

[[
  name: indexSelect
  python_name: index_select
  with_stateless: True
  return: argument 0
  arguments:
    - arg: THTensor* result
      output: True
    - THTensor* self
    - arg: int64_t dim
      wrap_dim: self
    - THIndexTensor* index
]]

[[
  name: indexCopy_
  python_name: index_copy_
  cname: indexCopy
  return: argument 0
  arguments:
    - THTensor* self
    - arg: int64_t dim
      wrap_dim: self
    - THIndexTensor* index
    - THTensor* source
]]

[[
  name: indexAdd_
  python_name: index_add_
  cname: indexAdd
  return: argument 0
  arguments:
    - THTensor* self
    - arg: int64_t dim
      wrap_dim: self
    - THIndexTensor* index
    - THTensor* source
]]

[[
  name: indexFill_
  python_name: index_fill_
  cname: indexFill
  return: argument 0
  arguments:
    - THTensor* self
    - arg: int64_t dim
      wrap_dim: self
    - THIndexTensor* index
    - real value
]]

[[
  name: narrow
  cpu_half: True
  auto_gpu: False
  return: argument 0
  arguments:
    - arg: THTensor* result
      output: True
    - THTensor* self
    - arg: int64_t dimension
      wrap_dim: self
    - int64_t start
    - int64_t length
]]

[[
  name: unfold
  cpu_half: True
  auto_gpu: False
  return: argument 0
  arguments:
    - arg: THTensor* result
      output: True
    - THTensor* self
    - arg: int64_t dimension
      wrap_dim: self
    - int64_t size
    - int64_t step
]]

[[
  name: range
  only_stateless: True
  defined_if: "!IS_CUDA"
  return: argument 0
  before_arg_assign: |
    PyErr_WarnEx(PyExc_UserWarning, "torch.range is deprecated in favor of torch.arange "
        "and will be removed in 0.3. Note that arange generates values in [start; end), "
        "not [start; end].", 1);
  arguments:
    - arg: THTensor* result
      output: True
    - accreal start
    - accreal end
    - arg: accreal step
      default: 1
]]

[[
  name: arange
  cname: range
  only_stateless: True
  defined_if: "!IS_CUDA"
  return: argument 0
  options:
    - before_call: |
        if (mod_traits<accreal>::mod(arg_end - arg_start, arg_step) == 0) {
          arg_end -= arg_step;
        }
      arguments:
        - arg: THTensor* result
          output: True
        - accreal start
        - accreal end
        - accreal step
    - before_call: |
        if (mod_traits<accreal>::mod(arg_end - arg_start, 1) == 0) {
          arg_end -= 1;
        }
      arguments:
        - arg: THTensor* result
          output: True
        - accreal start
        - accreal end
        - CONSTANT 1
]]

[[
  name: scatter_
  return: argument 0
  options:
    - cname: scatter
      arguments:
        - THTensor* self
        - arg: int64_t dim
          wrap_dim: self
        - THIndexTensor* index
        - THTensor* src
    - cname: scatterFill
      arguments:
        - THTensor* self
        - arg: int64_t dim
          wrap_dim: self
        - THIndexTensor* index
        - real value
]]

[[
  name: gather
  with_stateless: True
  return: argument 0
  before_call: |
    THLongStoragePtr _size = THIndexTensor_(newSizeOf)(LIBRARY_STATE arg_index);
    THTensor_(resize)(LIBRARY_STATE arg_result, _size, NULL);
  arguments:
    - arg: THTensor* result
      output: True
    - THTensor* self
    - arg: int64_t dim
      wrap_dim: self
    - THIndexTensor* index
]]

[[
  name: THPTensor_stateless_(cat)
  python_name: cat
  method_flags: METH_KEYWORDS
  only_register: True
  only_stateless: True
]]
#ifndef TH_REAL_IS_HALF
static PyObject * THPTensor_stateless_(cat)(THPTensor *_unused, PyObject *args, PyObject *kwargs)
{
  HANDLE_TH_ERRORS
#if IS_CUDA
  THCPAutoGPU __autogpu_guard(-1);
#endif
  static char* argnames[] = { "seq", "dim", "out", NULL };
  PyObject *_seq = NULL;
  long dim = 0;
  PyObject *___out = NULL;

  THPObjectPtr sequence;
  std::vector<THTensor *> tensors;
  THPTensorPtr result;
  Py_ssize_t len;

  if (!PyArg_ParseTupleAndKeywords(args, kwargs, "O|lO", argnames, &_seq, &dim, &___out)) {
    goto invalid_arguments;
  }

  sequence = PySequence_Fast(_seq, "seq must be a sequence");
  if (!sequence) {
    // NOTE: we use the error message from invalidArguments when _seq is not a sequence
    goto invalid_arguments;
  }

  len = PySequence_Fast_GET_SIZE(sequence.get());
  THPUtils_assert(len > 0, "seq can't be empty");

  if (___out && ___out != Py_None) {
    if (!THPTensor_(Check)(___out)) {
      goto invalid_arguments;
    }
    Py_INCREF(___out);
    result = (THPTensor *)___out;
  } else {
    result = (THPTensor *)THPTensor_(NewEmpty)();
    if (!result) return NULL;
  }

  for (int i = 0; i < len; i++) {
    PyObject *item = PySequence_Fast_GET_ITEM(sequence.get(), i);
    if (!THPTensor_(Check)(item))
      goto invalid_arguments;
    tensors.push_back(((THPTensor*)item)->cdata);
  }

  for (THTensor *t : tensors) {
    auto ndim = THTensor_(nDimension)(LIBRARY_STATE t);
    if (ndim > 0) {
      THPUtils_assert(dim > 0 ? dim < ndim : ndim + dim >= 0,
                      "dim out of range - got %d but the tensor is only %dD",
                      dim, ndim);
      if (dim < 0) dim += ndim;
      break;
    }
  }

#if IS_CUDA
  __autogpu_guard.setDevice(THTensor_(getDevice)(LIBRARY_STATE tensors[0]));
#endif

  THTensor_(catArray)(LIBRARY_STATE result->cdata, tensors.data(), (int) tensors.size(), dim);
  return (PyObject*)result.release();

invalid_arguments:
  THPUtils_invalidArguments(args, kwargs, "cat", 2,
      "(sequence[" THPTensorStr "] seq)",
      "(sequence[" THPTensorStr "] seq, int dim)");
  return NULL;
  END_HANDLE_TH_ERRORS
}
#endif

[[
  name: data_ptr
  return: void*
  cpu_half: True
  cname: data
  arguments:
    - THTensor* self
]]

[[
  name: equal
  with_stateless: True
  return: bool
  arguments:
    - THTensor* self
    - THTensor* other
]]

[[
  python_name: copy_
  name: THPTensor_(copy_)
  cpu_half: True
  method_flags: METH_KEYWORDS
  only_register: True
]]
PyObject * THPTensor_(copy_)(PyObject *self, PyObject *args, PyObject *kwargs)
{
  HANDLE_TH_ERRORS
  return THPCopyMethod(THTensor_(copy_functions), self, args, kwargs);
  END_HANDLE_TH_ERRORS
}
